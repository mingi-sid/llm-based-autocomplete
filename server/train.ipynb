{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-08-02 13:06:38,278] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "model_id = \"heegyu/kogpt-j-base\"\n",
    "rank = 8\n",
    "lora_alpha = 16\n",
    "max_length = 400\n",
    "\n",
    "batch_size = 1\n",
    "lr = 2e-4\n",
    "num_epochs = 1\n",
    "device = 'cuda'\n",
    "\n",
    "#tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/polyglot-ko-1.3b\", cache_dir=\"models\")\n",
    "#model = AutoModelForCausalLM.from_pretrained(\"EleutherAI/polyglot-ko-1.3b\", cache_dir=\"models\", device_map=\"auto\", load_in_8bit=True)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, cache_dir=\"models\")\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, cache_dir=\"models\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model.eval()\n",
    "_ = model.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, TaskType, PeftModel\n",
    "from peft import get_peft_config, get_peft_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load peft_config from json format\n",
    "import json\n",
    "model = PeftModel.from_pretrained(model, 'models/heegyu_kogpt-j-base_20230801015657/', is_trainable=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = '''마지막으로 사요를 본 지 몇 년이 지났다. 처음에는 사요가 단지 너무 바쁠 뿐이라고 답하던 양친도, 그런 거짓말을 믿기에는 너무 커버린 히나가 사요에 대해 캐물으면 대놓고 말을 돌렸다.'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    tokens = tokenizer(prompt, return_tensors='pt').to(device='cuda')\n",
    "    gen_tokens = model.generate(\n",
    "        input_ids=tokens['input_ids'],\n",
    "        attention_mask=tokens['attention_mask'],\n",
    "        do_sample=True,\n",
    "        temperature=0.9,\n",
    "        max_length=100,\n",
    "        top_k=10)\n",
    "    generated = tokenizer.batch_decode(gen_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "마지막으로 사요를 본 지 몇 년이 지났다. 처음에는 사요가 단지 너무 바쁠 뿐이라고 답하던 양친도, 그런 거짓말을 믿기에는 너무 커버린 히나가 사요에 대해 캐물으면 대놓고 말을 돌렸다.\n",
      "지푸라기라도 잡고 싶었던\n",
      "지푸라기라도 잡고싶어\n",
      "하지만 그 순간 지푸라기에서 나온 무언가가\n",
      "어두운 밤길을 걷는\n",
      "사소한 것들에 대한 집착이\n",
      "아무것도 남지 않았어\n",
      "그것은 바로\n",
      "다\n",
      "사라져 버린\n"
     ]
    }
   ],
   "source": [
    "print(generated[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Fine-tune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Parameter-Efficient Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): GPTJForCausalLM(\n",
       "      (transformer): GPTJModel(\n",
       "        (wte): Embedding(51200, 768)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "        (h): ModuleList(\n",
       "          (0-11): 12 x GPTJBlock(\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): GPTJAttention(\n",
       "              (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "              (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v_proj): Linear(\n",
       "                in_features=768, out_features=768, bias=False\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (q_proj): Linear(\n",
       "                in_features=768, out_features=768, bias=False\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (mlp): GPTJMLP(\n",
       "              (fc_in): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (fc_out): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (act): NewGELUActivation()\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (lm_head): Linear(in_features=768, out_features=51200, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 294,912 || all params: 163,990,016 || trainable%: 0.179835338268398\n"
     ]
    }
   ],
   "source": [
    "model.print_trainable_parameters()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Preparing Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./data/제로야슈_아침이 올 때까지.txt',\n",
       " './data/치요케이치요_연습.txt',\n",
       " './data/200822 인어사요.txt',\n",
       " './data/너의 날 선 상냥함으로 외전.txt',\n",
       " './data/사요히나 생일.txt',\n",
       " './data/히나츠구_한낮의 기다림.txt',\n",
       " './data/200312 사요린코사요.txt',\n",
       " './data/사요히나사요_수위190216.txt',\n",
       " './data/200816 교류회 원고.txt',\n",
       " './data/사요히나_너의 날선 상냥함으로.txt']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "text_files = glob('./data/*.txt')\n",
    "text_files[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    }
   ],
   "source": [
    "print(len(text_files))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d21482df12f24760b02635898b41d8b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset text/default to /home/smg/.cache/huggingface/datasets/text/default-611af0c7e5fe9a7a/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5e69135699e4b7a8b7808412442dac0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a8e2a3e8e39464b831560d5b9cedab1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0d845a870384ce09527bc7b8644cb9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset text downloaded and prepared to /home/smg/.cache/huggingface/datasets/text/default-611af0c7e5fe9a7a/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset('text', data_files=text_files, sample_by='document', split='train')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 20\n",
       "})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2TokenizerFast(name_or_path='heegyu/kogpt-j-base', vocab_size=51200, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>'}, clean_up_tokenization_spaces=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5474dcc2e93d4a60b774890b7140bedf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/20 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input_ids', 'attention_mask'],\n",
      "    num_rows: 20\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import re\n",
    "def preprocess_function(examples):\n",
    "    batch_size = len(examples[\"text\"])\n",
    "    # Remove redundant newlines\n",
    "    for i in range(batch_size):\n",
    "        examples[\"text\"] = re.sub(r\"\\n\\s*\\n\", \"\\n\", examples[\"text\"])\n",
    "    model_inputs = tokenizer(examples[\"text\"], padding='longest', return_tensors=\"pt\")\n",
    "    return model_inputs\n",
    "\n",
    "processed_datasets = dataset.map(\n",
    "    preprocess_function,\n",
    "    num_proc=1,\n",
    "    load_from_cache_file=False,\n",
    "    desc=\"Running tokenizer on dataset\",\n",
    "    remove_columns='text'\n",
    ")\n",
    "\n",
    "print(processed_datasets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['input_ids', 'attention_mask']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(processed_datasets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73a8c0c115c4438aa5f6adcb8170a223",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Chunking text:   0%|          | 0/20 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7871\n",
      "2909\n",
      "3317\n",
      "5544\n",
      "4155\n",
      "3789\n",
      "1522\n",
      "2724\n",
      "3437\n",
      "46784\n",
      "5784\n",
      "3517\n",
      "4386\n",
      "1643\n",
      "6635\n",
      "1315\n",
      "884\n",
      "2398\n",
      "3084\n",
      "1943\n",
      "7871\n",
      "2909\n",
      "3317\n",
      "5544\n",
      "4155\n",
      "3789\n",
      "1522\n",
      "2724\n",
      "3437\n",
      "46784\n",
      "5784\n",
      "3517\n",
      "4386\n",
      "1643\n",
      "6635\n",
      "1315\n",
      "884\n",
      "2398\n",
      "3084\n",
      "1943\n",
      "536\n",
      "(536, 400)\n",
      "Dataset({\n",
      "    features: ['input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 536\n",
      "})\n",
      "400\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def chunk_text(examples):\n",
    "    # Chunk into max_length tokens, return as a list of examples\n",
    "    result = {}\n",
    "    for k, v in examples.items():\n",
    "        value_chunks = []\n",
    "        v = sum(v, [])\n",
    "        for v2 in v:\n",
    "            print(len(v2))\n",
    "            for i in range(0, len(v2), max_length):\n",
    "                value_chunks.append(v2[i:i+max_length])\n",
    "            # Another examples, starting from half of max_length\n",
    "            for i in range(max_length//2, len(v2), max_length):\n",
    "                value_chunks.append(v2[i:i+max_length])\n",
    "        value_chunks = [x for x in value_chunks if len(x) == max_length]\n",
    "        result[k] = value_chunks[:]\n",
    "        result['labels'] = result['input_ids'].copy()\n",
    "    print(len(result['input_ids']))\n",
    "    print(np.array(result['input_ids']).shape)\n",
    "    return result\n",
    "\n",
    "chunked_dataset = processed_datasets.map(\n",
    "    chunk_text,\n",
    "    batched=True,\n",
    "    num_proc=1,\n",
    "    load_from_cache_file=False,\n",
    "    desc=\"Chunking text\",\n",
    ")\n",
    "print(chunked_dataset)\n",
    "print(max([len(x) for x in chunked_dataset['input_ids']]))\n",
    "#print('chunked_dataset[0]:', chunked_dataset[0])\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "assert np.array(chunked_dataset['input_ids']).shape == np.array(chunked_dataset['labels']).shape\n",
    "assert np.array(chunked_dataset['input_ids']).shape == np.array(chunked_dataset['attention_mask']).shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "\n",
      "아침이 올 때까지\n",
      "파이널판타지14\n",
      "제로 × 야슈톨라 룰\n",
      "※ 파이널판타지14 “효월의 종언” 6.2 버전까지의 스포일러를 포함하고 있습니다. 6.2 이후 스토리와는 설정충돌이 있을\n",
      "tensor(4.5662, device='cuda:0')\n",
      "19\n",
      "의 하늘 대신 그를 맞이하는 것은 시원한 바람과 푸른 하늘이다. 목 언저리까지 곧게 뻗은 머리카락이 바람에 비단이 물결치듯 일렁인다. 무심코 모자를 내리누르자, 두꺼운 갑주에서 덜\n",
      "tensor(4.0544, device='cuda:0')\n",
      "25\n",
      "둘 걸 그랬어요. 야슈톨라가 중얼거리는 소리가 들려왔다.\n",
      "습기로 가득한 대기와 끝없이 이어진 지평선은, 라자한의 풍경에 하늘 끝까지 불타오르는 듯한 노을을 만들어 낸다. 에테르를 \n",
      "tensor(4.0206, device='cuda:0')\n",
      "48\n",
      "마음이 반쯤 섞인 목소리로 되물었다. 이제 팔짱은 기본이 된 건지, 케이 옆에 딱 붙은 채였다. 케이의 어깨를 치요코의 머리카락이 간질였다. 케이는 치요코를 돌아보았다.\n",
      "\"별로야?\n",
      "tensor(4.0190, device='cuda:0')\n",
      "52\n",
      ". 어린 시절 사요와 온 성 안을 뛰어다닌, 정확히는 앞서가는 히나를 사요가 쫓아다닌 덕분이었다. 그 중 가장 유용했던 것은, 이젠 말라버린 호수정원 바닥에 있는 수로였다. 이 수\n",
      "tensor(4.0390, device='cuda:0')\n",
      "53\n",
      "일까? 바다생물일까? 강에서 나왔나? 저 멀리 밀림에는 강에 사는 사람만한 동물이 있다고 들었다. 여기에도 그런 동물이 있는 걸까?\n",
      "물이 끓어오르듯 한번에 기화점에 도달한 히나의 \n",
      "tensor(4.1125, device='cuda:0')\n",
      "57\n",
      " 바다생물일지도 몰라.\n",
      "어쩌면 인어일지도.\n",
      "그래. 바닷속에도 왕국이 있는 거야. 그리고 그곳의 공녀가 저녁노을이 보고 싶어서 여기로 오는 거야. 내가 그러는 것처럼.\n",
      "가슴이 뛰었다\n",
      "tensor(4.1597, device='cuda:0')\n",
      "58\n",
      " 신비한 괴물들.\n",
      "인어\n",
      "히나가 눈을 크게 떴다.\n",
      "사람의 아이로 태어나, 자라면 정체가 드러난다.\n",
      "낮에는 물속에서 살다가, 밤에는 사람들이 사는 곳으로 나온다.\n",
      "보름달이 뜨는 날, \n",
      "tensor(4.2213, device='cuda:0')\n",
      "60\n",
      "\n",
      "경치를 감상하던 히나가 눈꼬리를 올렸다. 해변의 커다란 바위 위에서 뭔가가 빛을 반사해 빛나고 있었다. 누군가 떨어뜨린 물건일까. 하지만 이 해변은 절벽으로 둘러싸여 있다. 도시\n",
      "tensor(4.0147, device='cuda:0')\n",
      "62\n",
      " 밤이 되면 자신과 언니를 기필코 떨어뜨려 놓은 것과 관계가 있는 걸까.\n",
      "답은 알 수 없었다. 그래도 실마리를 얻을 수는 있었다. 내일도 가 보자. 히나는 그렇게 결론지었다.\n",
      "히나\n",
      "tensor(4.0392, device='cuda:0')\n",
      "65\n",
      "는 무거운 시선으로, 물속에 반 쯤 잠긴 채 한들거리며, 무슨 일이 일어났는지도 모르고 다시 물에서 빠져나와 숨쉴 날을 기다리는 하늘색 꽃을 보았다. 수면 위로 흩어지는 노란색 꽃\n",
      "tensor(4.4691, device='cuda:0')\n",
      "66\n",
      "Extra 2. 현관\n",
      "“언니, 지금 해도 돼?”\n",
      "사요는 자신의 귀를 의심했다. 놓친 그릇이 싱크대 바닥을 나뒹굴며 요란한 소리를 냈다. 에이프런 위에 세제 거품이 튀었다. 그 냉기\n",
      "tensor(4.2621, device='cuda:0')\n",
      "69\n",
      " 과시하기라도 하듯이, 히나는 사요의 몸을 제멋대로 가지고 놀았다. 정해진 반응에 정해진 액션을 취하는 건, 히나의 특기 분야였다. 그렇게 히나는 누구도 모르는 사요를 알았다.\n",
      "사\n",
      "tensor(4.0124, device='cuda:0')\n",
      "71\n",
      "셔진 행위들을, 지금까지 해 왔다면, 단둘만 있는 집안에서 하는 것도 큰 차이는 없을 거라고. 그렇게 자기합리화를 하는 것은, 아마 지금 히나를 멈추기에는 그 감각이 너무나 매력적\n",
      "tensor(4.0510, device='cuda:0')\n",
      "72\n",
      " 메스꺼워져 왔다. 더 이상 견디기 어려웠다. 고개를 틀어 히나의 손을 빼냈다.\n",
      "“그만…… 됐으니까, 방으로.”\n",
      "“어차피 아무도 안 오는 걸?”\n",
      "그렇게 말하며 히나의 손동작은 계속\n",
      "tensor(4.0569, device='cuda:0')\n",
      "73\n",
      " 마룻바닥 위에는 사요의 흔적이 남았다. 그 흔적을 보자 오금이 저려왔다. 어떤 부연설명도 소용없는 현실로 끌어내려져, 스스로의 몸이 내놓은 단순한 반응을 마주했다. 수치스러워. \n",
      "tensor(4.1888, device='cuda:0')\n",
      "74\n",
      "자, 몸에서 긴장이 빠져나갔다. 히나는 두어 번 잇자국을 남기며 등줄기를 따라 열이 실린 호흡을 뱉었다. 마지막으로 도로 어깻죽지로 올라와, 한 손으로는 사요의 다리 사이에서 움직\n",
      "tensor(4.1131, device='cuda:0')\n",
      "82\n",
      " 사이로 애액이 스며나오는 몸이, 자신의 몸이 아닌 것처럼. 사요는 그렇게 스스로를 내려다 보았다.\n",
      "히나의 움직임은 좀 더 대담해져, 이제는 입에 넣은 손을 혓바닥 위로 미끄러뜨려\n",
      "tensor(4.1657, device='cuda:0')\n",
      "85\n",
      " 싶을 리 없었다. 도망쳐 봤자, 자신이 히나의 언니라는 사실로부터는 도망칠 수 없으니까. 그 사실은 어쩌면 영원히 사요의 이름 앞에 붙을 꼬리표나 마찬가지였다. 어차피 히나의 재\n",
      "tensor(4.1198, device='cuda:0')\n",
      "86\n",
      "고 들어와 순식간에 깊은 곳을 건드려왔다. 차가운 마루에 손을 짚은 사요가 몸을 떨었다.\n",
      "\"히나…….\"\n",
      "소용없다는 걸 알면서도 동생의 이름을 불렀다. 집중하고 있는 탓인지, 돌아오\n",
      "tensor(4.0927, device='cuda:0')\n",
      "87\n",
      " 역할이란 걸 알아도, 알기에, 더 그랬다. 히나는 그런 표정을 한 채로 사요의 몸에서 손을 뗐다. 몰래 손장난을 하다 들킨 아이처럼, 이해하지 못하는 깊은 죄책감 때문에 눈치를 \n",
      "tensor(4.1016, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for i in range(100):\n",
    "        text = tokenizer.decode(chunked_dataset[i]['input_ids'])[:100]\n",
    "        output = model(**{k: torch.LongTensor(v).to('cuda') for k, v in chunked_dataset[i].items()})\n",
    "        if output.loss.detach().cpu() > 4:\n",
    "            print(i)\n",
    "            print(text)\n",
    "            print(output.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "의 하늘 대신 그를 맞이하는 것은 시원한 바람과 푸른 하늘이다. 목 언저리까지 곧게 뻗은 머리카락이 바람에 비단이 물결치듯 일렁인다. 무심코 모자를 내리누르자, 두꺼운 갑주에서 덜거덕 소리가 난다.\n",
      "아마 이곳은 나의 고향과 가장 거리가 먼 곳이리라고 제로는 생각했다. 오직 허무만이 뭇 생명을 감싸고 있는 세계. 약육강식의 세계. 죽는 것마저 허락되지 않는 그곳에서, 공기에 깃든 경고를 미리 읽어내는 감각은 의미가 없었다.\n",
      "지금은 어디를 가나 공기가 메시지를 전하고 있다. 코를 자극하는 후추의 향이 제로에게는 그다지 불쾌하지 않았다. 후추, 아마 후추가 맞을 것이다, 라고 제로는 생각했다. 제로는 사라져 버린 감각들을 다시 제대로 이용하는 법을 배우는 중이었다. 새로운 생존방식에 익숙해지기 위해서였다. 특히, 엄청나게 매운 카레를 주는 대로 입에 넣었다가 모두의 앞에서 그대로 뱉어버린 뒤부터는, 다들 먹을 수 있을지 없을지 구별하는 법 정도는 배우라며 성화였다. 제로는 그런 요란스러움이 익숙하지 않았다. 하지만 싫지만도 않다고 생각했다.\n",
      "“어머, 그렇게 보다간 하늘에 구멍이 뚫리겠어요.”\n",
      "회상에 잠기던 제로에게 진담을 하는 건지 아닌지 모를 목소리가 들려왔다. 뒤를 돌아보자 그 익숙한 목소리의 주인이 팔짱을 낀 채 서 있었다. 한참 전부터 보고 있었을지도 모른다. 제로는 그렇게 생각하며 야슈톨라에게 되물었다.\n",
      "“……하늘에 구멍이 날 수가 있나?”\n",
      "순간 야슈톨라의 귀가 조금 쫑긋이는 듯 했다. 야슈톨라가 답했다.\n",
      "“후후, 농담이에요. 아직 유머감각은 익히지 않았나 봐요?”\n",
      "제로는 한숨을 내쉬었다.\n",
      "“……유한한 삶을 사는 인간이 그런 농담에 시간을 쓰러 여기까지 오다니, 정말 한가로운가 보군.”\n",
      "“어머, 비꼴 줄은 아는군요?”\n",
      "야슈톨라는 눈썹을 치켜세우며 한 치도 물러서지 않고 되받아쳤다. 그러다 조금 표정을\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(chunked_dataset[19]['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 누그러뜨리고 말을 이었다.\n",
      "“미안하지만 한가롭진 않았어요. 그런데 저랑 같이 바쁠 예정이던 어느 분이 못 나타나게 되었거든요.”\n",
      "“……그걸 내가 알아야 하는 이유가 있나?”\n",
      "“한가로운지 아닌지 먼저 물어본 건 당신 아니었나요?”\n",
      "야슈톨라는 다시 되받아치다가, 어떤 반발심도 없이 무표정한 제로의 얼굴을 보고 얕게 한숨을 쉬었다.\n",
      "“미안해요. 가끔…… 당신은 이유가 없으면 행동하지 않는 생활방식에 익숙해져 있다는 걸 잊어버리게 되네요.”\n",
      "“미안해 할 필요는 없다만.”\n",
      "제로는 그렇게 말하며 쓰고 있던 모자를 내리눌렀다. 잠깐의 침묵이 흘렀다. 자신이 한 말이 야슈톨라의 신경을 거슬렀다는 걸 제로도 아예 모르는 바는 아니었지만, 그렇다고 해서 적극적으로 기분을 풀어줄 마음도 없었다. 침묵을 지키고 있자, 눌러쓴 모자의 챙 너머에서 가벼운 박수 소리가 났다.\n",
      "“그럼 이건 어떨까요? 당신이 그 사람 대신에 시간 좀 내 줘요. 가벼운 데이트라고 할까요.”\n",
      "고개를 든 제로의 눈에 들어오는 건 뜻 모를 표정을 짓는 야슈톨라였다. 그 표정은 기분이 좋은 듯도, 놀리는 듯도 했다.\n",
      "“내가 거기에 응해서 얻는 게 있나?”\n",
      "“당신도 이 세계에서의 생활에 익숙해져야 하지 않겠어요? 언제까지나 이방인처럼 고독하게 살 수는 없잖아요.”\n",
      "“별로 상관은 없다만…….”\n",
      "야슈톨라는 그 말을 한숨으로 받았다. 이번에야말로 기분이 꽤 상한 건지, 발로 탁탁 차며 귀를 뒤로 젖혔다. 야슈톨라를 잘 아는 사람이라면 세계를 구한 영웅이라도 무심코 뒤로 물러나게 할 만큼 강한 분노의 표현이었다. 그러나 그것도 제로에게는 큰 효과가 없었다. 이윽고 야슈톨라가 포기했다는 듯 과장된 동작으로 양손을 들었다.\n",
      "“알았어요. 정말 손이 많이 가는군요. 그럼 이건 어때요? 오늘 하루 동안 가는대로 따라 와주면 에테르를 보충하게 해주겠어요.”\n",
      "제로는 눈을 치켜떴다. 그리고\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(chunked_dataset[20]['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bitsandbytes as bnb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args=transformers.TrainingArguments(\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        gradient_accumulation_steps=4,\n",
    "        warmup_steps=100, \n",
    "        num_train_epochs=num_epochs,\n",
    "        #max_steps=200,\n",
    "        learning_rate=lr, \n",
    "        fp16=True,\n",
    "        logging_steps=10, \n",
    "        optim='adafactor',\n",
    "        output_dir='outputs'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" from accelerate import Accelerator\n",
    "accelerator = Accelerator(mixed_precision='fp16')\n",
    "\n",
    "model.to(accelerator.device)\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    train_dataset=chunked_dataset,\n",
    "    args=training_args,\n",
    "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.cuda.amp.autocast(): \n",
    "    trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    tokens = tokenizer(prompt, return_tensors='pt').to(device='cuda')\n",
    "    gen_tokens = model.generate(\n",
    "        input_ids=tokens['input_ids'],\n",
    "        attention_mask=tokens['attention_mask'],\n",
    "        do_sample=True,\n",
    "        temperature=0.9,\n",
    "        max_length=100,\n",
    "        top_k=10,\n",
    "        repetition_penalty=10.0)\n",
    "    generated = tokenizer.batch_decode(gen_tokens)\n",
    "    print(generated[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save LoRA model with timestamp\n",
    "import datetime\n",
    "model_id = \"heegyu/kogpt-j-base\"\n",
    "model.save_pretrained(f\"models/{model_id.replace('/', '_')}_{datetime.datetime.now().strftime('%Y%m%d%H%M%S')}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
